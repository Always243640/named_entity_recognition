{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件编码: utf-8, 置信度: 0.99\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import os\n",
    "\n",
    "def detect_encoding_chardet(file_path):\n",
    "    \"\"\"\n",
    "    使用chardet库检测文件编码\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            raw_data = f.read()\n",
    "            result = chardet.detect(raw_data)\n",
    "            encoding = result['encoding']\n",
    "            confidence = result['confidence']\n",
    "            return encoding, confidence\n",
    "    except Exception as e:\n",
    "        return None, f\"错误: {str(e)}\"\n",
    "\n",
    "# 使用示例\n",
    "file_path = \"NER-test.txt\"\n",
    "encoding, confidence = detect_encoding_chardet(file_path)\n",
    "print(f\"文件编码: {encoding}, 置信度: {confidence:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T13:10:33.259333500Z",
     "start_time": "2025-11-18T13:10:31.139463400Z"
    }
   },
   "id": "d1cfb43c41f65963"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到原始编码: GB2312 (置信度: 0.99)\n",
      "检测编码读取失败，尝试常见编码...\n",
      "成功使用 gbk 编码读取\n",
      "成功转换为UTF-8格式: NER-train.txt\n",
      "原始编码: gbk → 转换后: UTF-8\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "import os\n",
    "\n",
    "def convert_to_utf8(file_path, output_path=None):\n",
    "    \"\"\"\n",
    "    自动检测文件编码并转换为UTF-8\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = file_path  # 原地转换\n",
    "    \n",
    "    # 检测原始编码\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        encoding_result = chardet.detect(raw_data)\n",
    "    \n",
    "    original_encoding = encoding_result['encoding']\n",
    "    confidence = encoding_result['confidence']\n",
    "    \n",
    "    print(f\"检测到原始编码: {original_encoding} (置信度: {confidence:.2f})\")\n",
    "    \n",
    "    # 尝试用检测到的编码读取并转换为UTF-8\n",
    "    try:\n",
    "        if original_encoding:\n",
    "            with open(file_path, 'r', encoding=original_encoding) as f:\n",
    "                content = f.read()\n",
    "        else:\n",
    "            raise UnicodeDecodeError(\"无法检测编码\")\n",
    "    except (UnicodeDecodeError, LookupError):\n",
    "        print(\"检测编码读取失败，尝试常见编码...\")\n",
    "        # 尝试常见编码\n",
    "        common_encodings = ['utf-8', 'gbk', 'gb2312','gb18030']\n",
    "        content = None\n",
    "        \n",
    "        for enc in common_encodings:\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding=enc) as f:\n",
    "                    content = f.read()\n",
    "                original_encoding = enc\n",
    "                print(f\"成功使用 {enc} 编码读取\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if content is None:\n",
    "            # 最后尝试忽略错误\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "            original_encoding = 'utf-8 (errors ignored)'\n",
    "    \n",
    "    # 写入UTF-8格式\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    print(f\"成功转换为UTF-8格式: {output_path}\")\n",
    "    return original_encoding\n",
    "\n",
    "# 使用示例\n",
    "file_path = \"NER-train-GBK.txt\"\n",
    "original_encoding = convert_to_utf8(file_path,output_path=\"NER-train.txt\")\n",
    "print(f\"原始编码: {original_encoding} → 转换后: UTF-8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T13:35:24.676842200Z",
     "start_time": "2025-11-18T13:35:12.943135600Z"
    }
   },
   "id": "1385a1fc5121b49e"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 迈 N\n",
      "2: 向 N\n",
      "3: 充 N\n",
      "4: 满 N\n",
      "5: 希 N\n",
      "6: 望 N\n",
      "7: 的 N\n",
      "8: 新 N\n",
      "9: 世 N\n",
      "10: 纪 N\n"
     ]
    }
   ],
   "source": [
    "def view_first_lines(file_path, num_lines=10):\n",
    "    \"\"\"查看文件前几行\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= num_lines:\n",
    "                break\n",
    "            print(f\"{i+1}: {line}\", end='')\n",
    "\n",
    "# 使用示例\n",
    "view_first_lines('NER-train.txt', 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T13:35:51.263556100Z",
     "start_time": "2025-11-18T13:35:51.258473100Z"
    }
   },
   "id": "a049121c7e8d7c6d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始转换BIN标记到BMES标记...\n",
      "转换完成！结果已保存到 dev.char.bmes\n",
      "\n",
      "转换前后对比示例：\n",
      "原数据（BIN格式）：\n",
      "国 B-ORG\n",
      "家 I-ORG\n",
      "禁 I-ORG\n",
      "毒 I-ORG\n",
      "委 I-ORG\n",
      "员 I-ORG\n",
      "会 I-ORG\n",
      "副 N\n",
      "主 N\n",
      "任 N\n",
      "\n",
      "转换后（BMES格式）：\n",
      "国 B-ORG\n",
      "家 M-ORG\n",
      "禁 M-ORG\n",
      "毒 M-ORG\n",
      "委 M-ORG\n",
      "员 M-ORG\n",
      "会 E-ORG\n",
      "副 O\n",
      "主 O\n",
      "任 O\n"
     ]
    }
   ],
   "source": [
    "def convert_bin_to_bmes(input_file, output_file):\n",
    "    \"\"\"\n",
    "    将BIN标记格式转换为BMES标记格式\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        \n",
    "        lines = f_in.readlines()\n",
    "        total_lines = len(lines)\n",
    "        \n",
    "        i = 0\n",
    "        while i < total_lines:\n",
    "            current_line = lines[i].strip()\n",
    "            \n",
    "            # 跳过空行\n",
    "            if not current_line:\n",
    "                f_out.write('\\n')\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # 分割字符和标签\n",
    "            parts = current_line.split()\n",
    "            if len(parts) < 2:\n",
    "                f_out.write(current_line + '\\n')\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            char, label = parts[0], parts[1]\n",
    "            \n",
    "            # 规则1: B-* 标签保持不变\n",
    "            if label.startswith('B-'):\n",
    "                f_out.write(f\"{char} {label}\\n\")\n",
    "            \n",
    "            # 规则3: N 标签改为 O\n",
    "            elif label == 'N':\n",
    "                f_out.write(f\"{char} O\\n\")\n",
    "            \n",
    "            # 规则2: I-* 标签的处理\n",
    "            elif label.startswith('I-'):\n",
    "                entity_type = label.split('-')[1]  # 提取实体类型\n",
    "                \n",
    "                # 检查下一个字符\n",
    "                if i + 1 < total_lines:\n",
    "                    next_line = lines[i + 1].strip()\n",
    "                    if next_line:\n",
    "                        next_parts = next_line.split()\n",
    "                        if len(next_parts) >= 2:\n",
    "                            next_label = next_parts[1]\n",
    "                            \n",
    "                            # 如果下一个标签也是I-*，当前标签改为M-*\n",
    "                            if next_label.startswith('I-'):\n",
    "                                new_label = f\"M-{entity_type}\"\n",
    "                                f_out.write(f\"{char} {new_label}\\n\")\n",
    "                            # 如果下一个标签不是I-*，当前标签改为E-*\n",
    "                            else:\n",
    "                                new_label = f\"E-{entity_type}\"\n",
    "                                f_out.write(f\"{char} {new_label}\\n\")\n",
    "                        else:\n",
    "                            # 下一行格式不正确，当前标签改为E-*\n",
    "                            new_label = f\"E-{entity_type}\"\n",
    "                            f_out.write(f\"{char} {new_label}\\n\")\n",
    "                    else:\n",
    "                        # 下一行为空行，当前标签改为E-*\n",
    "                        new_label = f\"E-{entity_type}\"\n",
    "                        f_out.write(f\"{char} {new_label}\\n\")\n",
    "                else:\n",
    "                    # 当前是最后一行，标签改为E-*\n",
    "                    new_label = f\"E-{entity_type}\"\n",
    "                    f_out.write(f\"{char} {new_label}\\n\")\n",
    "            \n",
    "            # 其他标签（如O等）保持不变\n",
    "            else:\n",
    "                f_out.write(f\"{char} {label}\\n\")\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "def main():\n",
    "    input_file = \"NER-dev.txt\"\n",
    "    output_file = \"dev.char.bmes\"\n",
    "    \n",
    "    print(\"开始转换BIN标记到BMES标记...\")\n",
    "    convert_bin_to_bmes(input_file, output_file)\n",
    "    print(f\"转换完成！结果已保存到 {output_file}\")\n",
    "    \n",
    "    # 显示转换前后的对比示例\n",
    "    print(\"\\n转换前后对比示例：\")\n",
    "    print(\"原数据（BIN格式）：\")\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        sample_lines = []\n",
    "        for i, line in enumerate(f):\n",
    "            if line.strip():\n",
    "                sample_lines.append(line.strip())\n",
    "            if len(sample_lines) >= 10:\n",
    "                break\n",
    "        for line in sample_lines:\n",
    "            print(line)\n",
    "    \n",
    "    print(\"\\n转换后（BMES格式）：\")\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        sample_lines = []\n",
    "        for i, line in enumerate(f):\n",
    "            if line.strip():\n",
    "                sample_lines.append(line.strip())\n",
    "            if len(sample_lines) >= 10:\n",
    "                break\n",
    "        for line in sample_lines:\n",
    "            print(line)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T13:37:48.264600800Z",
     "start_time": "2025-11-18T13:37:48.083484200Z"
    }
   },
   "id": "bb4a4faf4835b017"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总句子数: 47317\n",
      "训练集句子数: 42585\n",
      "验证集句子数: 4732\n",
      "数据集划分完成！\n",
      "训练集已保存至: NER-train.txt\n",
      "验证集已保存至: NER-dev.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def split_ner_dataset(input_file, train_file, dev_file, split_ratio=0.9):\n",
    "    \"\"\"\n",
    "    将NER数据集按指定比例划分为训练集和验证集\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入文件路径\n",
    "        train_file: 训练集输出文件路径\n",
    "        dev_file: 验证集输出文件路径\n",
    "        split_ratio: 训练集比例，默认为0.9\n",
    "    \"\"\"\n",
    "    \n",
    "    # 读取原始数据\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # 按句子分割数据（空行分隔）\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:  # 非空行\n",
    "            current_sentence.append(line)\n",
    "        else:  # 空行表示句子结束\n",
    "            if current_sentence:\n",
    "                sentences.append(current_sentence)\n",
    "                current_sentence = []\n",
    "    \n",
    "    # 添加最后一个句子（如果存在）\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "    \n",
    "    print(f\"总句子数: {len(sentences)}\")\n",
    "    \n",
    "    # 随机打乱句子\n",
    "    random.seed(42)  # 设置随机种子以保证可重复性\n",
    "    random.shuffle(sentences)\n",
    "    \n",
    "    # 计算分割点\n",
    "    split_point = int(len(sentences) * split_ratio)\n",
    "    train_sentences = sentences[:split_point]\n",
    "    dev_sentences = sentences[split_point:]\n",
    "    \n",
    "    print(f\"训练集句子数: {len(train_sentences)}\")\n",
    "    print(f\"验证集句子数: {len(dev_sentences)}\")\n",
    "    \n",
    "    # 写入训练集\n",
    "    with open(train_file, 'w', encoding='utf-8') as f:\n",
    "        for sentence in train_sentences:\n",
    "            for line in sentence:\n",
    "                f.write(line + '\\n')\n",
    "            f.write('\\n')  # 句子间用空行分隔\n",
    "    \n",
    "    # 写入验证集\n",
    "    with open(dev_file, 'w', encoding='utf-8') as f:\n",
    "        for sentence in dev_sentences:\n",
    "            for line in sentence:\n",
    "                f.write(line + '\\n')\n",
    "            f.write('\\n')  # 句子间用空行分隔\n",
    "    \n",
    "    print(\"数据集划分完成！\")\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"NER-train.txt\"\n",
    "    train_output = \"NER-train.txt\"  # 为避免覆盖原文件，使用新名称\n",
    "    dev_output = \"NER-dev.txt\"\n",
    "    \n",
    "    split_ner_dataset(input_file, train_output, dev_output)\n",
    "    \n",
    "    print(f\"训练集已保存至: {train_output}\")\n",
    "    print(f\"验证集已保存至: {dev_output}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-18T13:36:17.238600800Z",
     "start_time": "2025-11-18T13:36:15.394084400Z"
    }
   },
   "id": "8a2f46b44902f6d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c6e2d8ec2563d21c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
