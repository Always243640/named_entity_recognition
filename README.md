# 中文命名实体识别
 
## 项目简介
 
本项目尝试使用多种模型（包括 HMM、CRF、Bi-LSTM、Bi-LSTM+CRF）解决中文命名实体识别问题，核心数据来自论文 ACL 2018 [Chinese NER using Lattice LSTM](https://github.com/jiesutd/LatticeLSTM) 收集的简历数据。模型训练与推理的主要入口位于项目根目录下的 `main.py` 和 `test.py`，同时提供 GUI（`gui_app/main.py`）便于选择模型进行训练、测评与交互式体验。

## 目录结构

以下为项目主要目录和文件的作用说明：

- `main.py`：重新训练全部模型（HMM、CRF、Bi-LSTM、Bi-LSTM+CRF）。
- `test.py`：加载已训练模型并重新测评。
- `output.txt`：作者本人测评时的实验输出，可作为评估时的预期对照。
- `gui_app/`：图形界面实现，运行 `gui_app/main.py` 会弹出窗口，支持选择模型进行训练和测评，并可输入测试语句查看标注结果。
- `models/`：各模型的实现与配置（如 `config.py`）。
- `ckpts/`：模型保存路径（训练后生成）。
- `imgs/`：README 中使用的示意图。
- `requirement.txt`、`requirements.txt`：项目依赖列表。
 
-该数据集就位于项目目录下的`ResumeNER`文件夹里。
+## 使用指南
 
-## 运行结果
+1. 安装依赖
 
-下面是四种不同的模型以及这Ensemble这四个模型预测结果的准确率（取最好）：
+   ```bash
+   pip3 install -r requirements.txt
+   ```
 
-|      | HMM    | CRF    | BiLSTM | BiLSTM+CRF | Ensemble |
-| ---- | ------ | ------ | ------ | ---------- | -------- |
-| 召回率  | 91.22% | 95.43% | 95.32% | 95.72%     | 95.65%   |
-| 准确率  | 91.49% | 95.43% | 95.37% | 95.74%     | 95.69%   |
-| F1分数 | 91.30% | 95.42% | 95.32% | 95.70%     | 95.64%   |
+2. 重新训练并评估全部模型
 
-最后一列Ensemble是将这四个模型的预测结果结合起来，使用“投票表决”的方法得出最后的预测结果。
+   ```bash
+   python3 main.py
+   ```
 
-（Ensemble的三个指标均不如BiLSTM+CRF，可以认为在Ensemble过程中，是其他三个模型拖累了BiLSTM+CRF）
+   运行后会训练 HMM、CRF、Bi-LSTM、Bi-LSTM+CRF，并在控制台输出精确率、召回率、F1 分数以及混淆矩阵。若需调整模型或训练参数，可编辑 `models/config.py`。
 
-具体的输出可以查看`output.txt`文件。
+3. 仅加载并测评已有模型
 
+   ```bash
+   python3 test.py
+   ```
 
+   评估结果可与 `output.txt` 中的预期输出进行对照。
 
-## 快速开始
+4. 体验图形界面
 
-首先安装依赖项：
+   ```bash
+   python3 gui_app/main.py
+   ```
 
-```
-pip3 install -r requirement.txt
-```
+   程序会弹出窗口，可选择指定模型进行训练与测评，并可输入测试语句查看模型的标注效果。
 
-安装完毕之后，直接使用
+## 数据集
+
+数据集的格式如下，每一行由一个字及其对应的标注组成，标注集采用 BIOES，句子之间用一个空行隔开。
 
 ```
-python3 main.py
+美      B-LOC
+国      E-LOC
+的      O
+华      B-PER
+莱      I-PER
+士      E-PER
+
+我      O
+跟      O
+他      O
+谈      O
+笑      O
+风      O
+生      O
 ```
 
-即可训练以及评估模型，评估模型将会打印出模型的精确率、召回率、F1分数值以及混淆矩阵，如果想要修改相关模型参数或者是训练参数，可以在`./models/config.py`文件中进行设置。
+该数据集就位于项目目录下的 `ResumeNER` 文件夹里。
+
+## 运行结果
 
-训练完毕之后，如果想要加载并评估模型，运行如下命令：
+下面是四种不同的模型以及 Ensemble 结合四个模型预测结果的准确率（取最好）：
 
-```shell
-python3 test.py
-```
+|      | HMM    | CRF    | BiLSTM | BiLSTM+CRF | Ensemble |
+| ---- | ------ | ------ | ------ | ---------- | -------- |
+| 召回率  | 91.22% | 95.43% | 95.32% | 95.72%     | 95.65%   |
+| 准确率  | 91.49% | 95.43% | 95.37% | 95.74%     | 95.69%   |
+| F1分数 | 91.30% | 95.42% | 95.32% | 95.70%     | 95.64%   |
+
+最后一列 Ensemble 是将这四个模型的预测结果结合起来，使用“投票表决”的方法得出最后的预测结果。
 
-下面是这些模型的简单介绍（github网页对数学公式的支持不太好，涉及公式的部分无法正常显示，[我的博客](https://zhuanlan.zhihu.com/p/61227299)  有对这些模型以及代码更加详细的介绍）：
+（Ensemble 的三个指标均不如 BiLSTM+CRF，可以认为在 Ensemble 过程中，是其他三个模型拖累了 BiLSTM+CRF）
 
+具体的输出可以查看 `output.txt` 文件。
 
+下面是这些模型的简单介绍（GitHub 网页对数学公式的支持不太好，涉及公式的部分无法正常显示，[我的博客](https://zhuanlan.zhihu.com/p/61227299)  有对这些模型以及代码更加详细的介绍）：
 
 ## 隐马尔可夫模型（Hidden Markov Model，HMM）	 
 
 隐马尔可夫模型描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程（李航 统计学习方法）。隐马尔可夫模型由初始状态分布，状态转移概率矩阵以及观测概率矩阵所确定。
 
 命名实体识别本质上可以看成是一种序列标注问题，在使用HMM解决命名实体识别这种序列标注问题的时候，我们所能观测到的是字组成的序列（观测序列），观测不到的是每个字对应的标注（状态序列）。
 
 **初始状态分布**就是每一个标注的初始化概率，**状态转移概率矩阵**就是由某一个标注转移到下一个标注的概率（就是若前一个词的标注为$tag_i$ ，则下一个词的标注为$tag_j$的概率为 $M_{ij}$），**观测概率矩阵**就是指在
 
 某个标注下，生成某个词的概率。
 
 HMM模型的训练过程对应隐马尔可夫模型的学习问题（李航 统计学习方法），
 
 实际上就是根据训练数据根据最大似然的方法估计模型的三个要素，即上文提到的初始状态分布、状态转移概率矩阵以及观测概率矩阵，模型训练完毕之后，利用模型进行解码，即对给定观测序列，求它对应的状态序列，这里就是对给定的句子，求句子中的每个字对应的标注，针对这个解码问题，我们使用的是维特比（viterbi）算法。
 
 具体的细节可以查看 `models/hmm.py`文件。
 
 
 
 
 
 ## 条件随机场（Conditional Random Field, CRF)
 
  HMM模型中存在两个假设，一是输出观察值之间严格独立，二是状态转移过程中当前状态只与前一状态有关。也就是说，在命名实体识别的场景下，HMM认为观测到的句子中的每个字都是相互独立的，而且当前时刻的标注只与前一时刻的标注相关。但实际上，命名实体识别往往需要更多的特征，比如词性，词的上下文等等，同时当前时刻的标注应该与前一时刻以及后一时刻的标注都相关联。由于这两个假设的存在，显然HMM模型在解决命名实体识别的问题上是存在缺陷的。
 
