{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# æ¨¡å‹é”™è¯¯ç±»å‹åˆ†æè„šæœ¬\n",
    "# è¯¥è„šæœ¬ä¼šåŠ è½½å·²è®­ç»ƒå¥½çš„ BiLSTM+CRF æ¨¡å‹ï¼Œå¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
    "project_root = Path(\".\").resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from typing import DefaultDict, Dict, List, Sequence, Tuple\n",
    "try:\n",
    "    from data import build_corpus\n",
    "    from evaluating import Metrics\n",
    "    from utils import extend_maps, load_model, prepocess_data_for_lstmcrf\n",
    "except ImportError as e:\n",
    "    print(f\"å¯¼å…¥é”™è¯¯: {e}\")\n",
    "    print(\"è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤ Notebookï¼Œä¸”ç›¸å…³æ¨¡å—å¯ç”¨\")\n",
    "DEFAULT_MODEL_PATH = Path(\".\").resolve() / \"ckpts\" / \"bilstm_crf.pkl\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fb753ba01abc35e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _ensure_best_model(model) -> None:\n",
    "    \"\"\"ä¿è¯ååºåˆ—åŒ–åçš„æ¨¡å‹å¯ä»¥ç›´æ¥ç”¨äºé¢„æµ‹ã€‚\"\"\"\n",
    "    if model.best_model is None:\n",
    "        model.best_model = deepcopy(model.model)\n",
    "    # å»é™¤ PackedSequence çš„è­¦å‘Šï¼Œå…¼å®¹ GPU/CPU\n",
    "    if hasattr(model.best_model, \"bilstm\"):\n",
    "        bilstm_block = getattr(model.best_model, \"bilstm\")\n",
    "        if hasattr(bilstm_block, \"bilstm\"):\n",
    "            bilstm_block.bilstm.flatten_parameters()\n",
    "\n",
    "def _extract_entities_bmes(words: Sequence[str], tags: Sequence[str]) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    å°† BMES æ ‡æ³¨è½¬æ¢ä¸ºå®ä½“åˆ—è¡¨ã€‚\n",
    "    \"\"\"\n",
    "    entities: List[Dict[str, str]] = []\n",
    "    i = 0\n",
    "    n = len(tags)\n",
    "    \n",
    "    while i < n:\n",
    "        tag = tags[i]\n",
    "        \n",
    "        if tag.startswith(\"B-\"):\n",
    "            # å¤„ç†å¤šå­—å®ä½“ï¼šB -> M* -> E\n",
    "            entity_type = tag[2:]\n",
    "            start = i\n",
    "            j = i + 1\n",
    "            \n",
    "            # å¯»æ‰¾è¿ç»­çš„Mæ ‡ç­¾ï¼ˆåŒç±»å‹ï¼‰\n",
    "            while j < n and tags[j] == f\"M-{entity_type}\":\n",
    "                j += 1\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦ä»¥Eæ ‡ç­¾ç»“æŸï¼ˆåŒç±»å‹ï¼‰\n",
    "            if j < n and tags[j] == f\"E-{entity_type}\":\n",
    "                end = j + 1  # Eæ ‡ç­¾åŒ…å«åœ¨å®ä½“ä¸­\n",
    "                entity_text = \"\".join(words[start:end])\n",
    "                entities.append({\n",
    "                    \"type\": entity_type, \n",
    "                    \"text\": entity_text, \n",
    "                    \"span\": f\"{start}-{end}\"\n",
    "                })\n",
    "                i = end\n",
    "            else:\n",
    "                # ä¸ç¬¦åˆBMESè§„èŒƒï¼Œè·³è¿‡è¿™ä¸ªBæ ‡ç­¾\n",
    "                i += 1\n",
    "                \n",
    "        elif tag == \"O\":\n",
    "            # éå®ä½“ï¼Œç›´æ¥è·³è¿‡\n",
    "            i += 1\n",
    "            \n",
    "        else:\n",
    "            # é‡åˆ°Mæˆ–Eä½†æ²¡æœ‰å¯¹åº”çš„Bï¼Œè·³è¿‡\n",
    "            i += 1\n",
    "            \n",
    "    return entities\n",
    "\n",
    "def _extract_entities_bmes_relaxed(words: Sequence[str], tags: Sequence[str]) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    å®½æ¾çš„BMESå®ä½“æå–ã€‚\n",
    "    å°†è¿ç»­çš„B/M/Eï¼ˆåŒç±»å‹ï¼‰è§†ä¸ºä¸€ä¸ªå®ä½“ï¼Œå³ä½¿ä¸­é—´æœ‰è½»å¾®çš„ä¸è§„èŒƒã€‚\n",
    "    \"\"\"\n",
    "    entities: List[Dict[str, str]] = []\n",
    "    i = 0\n",
    "    n = len(tags)\n",
    "    \n",
    "    while i < n:\n",
    "        tag = tags[i]\n",
    "        \n",
    "        if tag.startswith(\"B-\"):\n",
    "            entity_type = tag[2:]\n",
    "            start = i\n",
    "            end = i + 1\n",
    "            \n",
    "            # å¯»æ‰¾è¿ç»­çš„åŒç±»æ ‡ç­¾\n",
    "            j = i + 1\n",
    "            while j < n:\n",
    "                current_tag = tags[j]\n",
    "                if (current_tag == f\"M-{entity_type}\" or \n",
    "                    current_tag == f\"E-{entity_type}\"):\n",
    "                    end = j + 1\n",
    "                    j += 1\n",
    "                    # å¦‚æœé‡åˆ°Eæ ‡ç­¾ï¼Œåœæ­¢æœç´¢\n",
    "                    if current_tag.startswith(\"E-\"):\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            entity_text = \"\".join(words[start:end])\n",
    "            entities.append({\n",
    "                \"type\": entity_type,\n",
    "                \"text\": entity_text, \n",
    "                \"span\": f\"{start}-{end}\"\n",
    "            })\n",
    "            i = end\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "    return entities\n",
    "\n",
    "def _format_entities(entities: Sequence[Dict[str, str]]) -> str:\n",
    "    \"\"\"æ ¼å¼åŒ–å®ä½“åˆ—è¡¨ç”¨äºæ˜¾ç¤º\"\"\"\n",
    "    if not entities:\n",
    "        return \"(æ— )\"\n",
    "    return \" | \".join(f\"{e['type']}:ã€{e['text']}ã€[{e['span']}]\" for e in entities)\n",
    "\n",
    "def _collect_errors(\n",
    "    sentences: Sequence[Sequence[str]],\n",
    "    golden_tags: Sequence[Sequence[str]],\n",
    "    pred_tags: Sequence[Sequence[str]],\n",
    "    max_examples_per_type: int = 3,\n",
    ") -> Tuple[Counter, DefaultDict[str, List[Dict[str, str]]]]:\n",
    "    \"\"\"ç»Ÿè®¡é”™è¯¯ç±»å‹å¹¶è¿”å›å…¸å‹æ¡ˆä¾‹ã€‚\"\"\"\n",
    "    error_counter: Counter = Counter()\n",
    "    error_examples: DefaultDict[str, List[Dict[str, str]]] = defaultdict(list)\n",
    "\n",
    "    for words, gold_seq, pred_seq in zip(sentences, golden_tags, pred_tags):\n",
    "        gold_entities = _extract_entities_bmes_relaxed(words, gold_seq)\n",
    "        pred_entities = _extract_entities_bmes_relaxed(words, pred_seq)\n",
    "\n",
    "        for idx, (gold, pred) in enumerate(zip(gold_seq, pred_seq)):\n",
    "            if gold != pred:\n",
    "                error_type = f\"{gold}->{pred}\"\n",
    "                error_counter[error_type] += 1\n",
    "                if len(error_examples[error_type]) < max_examples_per_type:\n",
    "                    error_examples[error_type].append(\n",
    "                        {\n",
    "                            \"sentence\": \"\".join(words),\n",
    "                            \"words\": words,\n",
    "                            \"gold_tags\": gold_seq,\n",
    "                            \"pred_tags\": pred_seq,\n",
    "                            \"gold_entities\": gold_entities,\n",
    "                            \"pred_entities\": pred_entities,\n",
    "                        }\n",
    "                    )\n",
    "    return error_counter, error_examples"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc9d7fb126ebffb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(model_path: Path = DEFAULT_MODEL_PATH, remove_o: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    model_path : Path\n",
    "        æ¨¡å‹æ–‡ä»¶è·¯å¾„\n",
    "    remove_o : bool\n",
    "        æ˜¯å¦åœ¨è¯„ä¼°æ—¶å¿½ç•¥Oæ ‡ç­¾\n",
    "    Returns:dict: åŒ…å«è¯„ä¼°ç»“æœçš„å­—å…¸\n",
    "    \"\"\"\n",
    "    print(\"è¯»å–æ•°æ®...\")\n",
    "    try:\n",
    "        _, _, word2id, tag2id = build_corpus(\"train\")\n",
    "        test_word_lists, test_tag_lists = build_corpus(\"test\", make_vocab=False)\n",
    "    except Exception as e:\n",
    "        print(f\"æ•°æ®è¯»å–å¤±è´¥: {e}\")\n",
    "        return {}\n",
    "\n",
    "    # ä¿ç•™åŸå§‹å¥å­ï¼Œä¾¿äºå±•ç¤ºé”™è¯¯æ¡ˆä¾‹\n",
    "    display_word_lists = [list(seq) for seq in test_word_lists]\n",
    "\n",
    "    crf_word2id, crf_tag2id = extend_maps(word2id, tag2id, for_crf=True)\n",
    "    test_word_lists, test_tag_lists = prepocess_data_for_lstmcrf(\n",
    "        test_word_lists, test_tag_lists, test=True\n",
    "    )\n",
    "\n",
    "    print(f\"åŠ è½½æ¨¡å‹: {model_path}\")\n",
    "    try:\n",
    "        bilstm_model = load_model(str(model_path))\n",
    "        _ensure_best_model(bilstm_model)\n",
    "    except Exception as e:\n",
    "        print(f\"æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "        return {}\n",
    "\n",
    "    print(\"å¼€å§‹é¢„æµ‹...\")\n",
    "    pred_tag_lists, target_tag_lists = bilstm_model.test(\n",
    "        test_word_lists, test_tag_lists, crf_word2id, crf_tag2id\n",
    "    )\n",
    "\n",
    "    print(\"\\nåŸºç¡€è¯„ä¼°æŒ‡æ ‡ï¼š\")\n",
    "    metrics = Metrics(target_tag_lists, pred_tag_lists, remove_O=remove_o)\n",
    "    metrics.report_scores()\n",
    "\n",
    "    error_counter, error_examples = _collect_errors(\n",
    "        display_word_lists, target_tag_lists, pred_tag_lists\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'error_counter': error_counter,\n",
    "        'error_examples': error_examples,\n",
    "        'pred_tags': pred_tag_lists,\n",
    "        'true_tags': target_tag_lists,\n",
    "        'sentences': display_word_lists\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdb48cee508ce7fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# äº¤äº’å¼é”™è¯¯åˆ†æå‡½æ•°\n",
    "def interactive_error_analysis(results, error_type: str = None, max_examples: int = 5):\n",
    "    \"\"\"\n",
    "    results : dict\n",
    "        evaluate_model å‡½æ•°çš„è¿”å›ç»“æœ\n",
    "    error_type : str, optional\n",
    "        æŒ‡å®šè¦æŸ¥çœ‹çš„é”™è¯¯ç±»å‹ï¼Œå¦‚ 'B-PER->O'\n",
    "    max_examples : int\n",
    "        æœ€å¤§æ˜¾ç¤ºæ¡ˆä¾‹æ•°é‡\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"æ²¡æœ‰å¯ç”¨çš„ç»“æœ\")\n",
    "        return\n",
    "        \n",
    "    error_counter = results['error_counter']\n",
    "    error_examples = results['error_examples']\n",
    "    \n",
    "    # print(\"æ‰€æœ‰é”™è¯¯ç±»å‹ç»Ÿè®¡:\")\n",
    "    # for i, (err_type, count) in enumerate(error_counter.most_common()):\n",
    "    #     print(f\"{i+1:2d}. {err_type}: {count}\")\n",
    "    \n",
    "    if error_type:\n",
    "        if error_type in error_examples:\n",
    "            examples = error_examples[error_type][:max_examples]\n",
    "            print(f\"\\nè¯¦ç»†æŸ¥çœ‹é”™è¯¯ç±»å‹: {error_type} (æ˜¾ç¤º{len(examples)}ä¸ªæ¡ˆä¾‹)\")\n",
    "            for j, case in enumerate(examples):\n",
    "                print(f\"\\n--- æ¡ˆä¾‹ {j+1} ---\")\n",
    "                print(f\"å¥å­: {case['sentence']}\")\n",
    "                print(f\"å­—/è¯: {' '.join(case['words'])}\")\n",
    "                # print(f\"Goldæ ‡ç­¾: {' '.join(case['gold_tags'])}\")\n",
    "                # print(f\"Predæ ‡ç­¾: {' '.join(case['pred_tags'])}\")\n",
    "                print(f\"Goldå®ä½“: {_format_entities(case['gold_entities'])}\")\n",
    "                print(f\"Predå®ä½“: {_format_entities(case['pred_entities'])}\")\n",
    "                print(\"-\" * 60)\n",
    "        else:\n",
    "            print(f\"é”™è¯¯ç±»å‹ '{error_type}' ä¸å­˜åœ¨\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6fe68664ad610ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# å®ä½“å¯¹æ¯”åˆ†æå‡½æ•°\n",
    "def compare_entities(results, sentence_index: int):\n",
    "    \"\"\"\n",
    "    å¯¹æ¯”ç‰¹å®šå¥å­çš„å®ä½“è¯†åˆ«ç»“æœ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        evaluate_model å‡½æ•°çš„è¿”å›ç»“æœ\n",
    "    sentence_index : int\n",
    "        è¦åˆ†æçš„å¥å­ç´¢å¼•\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"æ²¡æœ‰å¯ç”¨çš„ç»“æœ\")\n",
    "        return\n",
    "        \n",
    "    sentences = results['sentences']\n",
    "    true_tags = results['true_tags']\n",
    "    pred_tags = results['pred_tags']\n",
    "    \n",
    "    if sentence_index >= len(sentences):\n",
    "        print(f\"å¥å­ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œæœ€å¤§ç´¢å¼•ä¸º {len(sentences)-1}\")\n",
    "        return\n",
    "    \n",
    "    words = sentences[sentence_index]\n",
    "    gold_tags = true_tags[sentence_index]\n",
    "    pred_tags_seq = pred_tags[sentence_index]\n",
    "    \n",
    "    gold_entities = _extract_entities_bmes_relaxed(words, gold_tags)\n",
    "    pred_entities = _extract_entities_bmes_relaxed(words, pred_tags_seq)\n",
    "    \n",
    "    print(f\"å¥å­ {sentence_index} åˆ†æ:\")\n",
    "    print(f\"æ–‡æœ¬: {''.join(words)}\")\n",
    "    print(f\"å­—/è¯: {' '.join(words)}\")\n",
    "    # print(f\"Goldæ ‡ç­¾: {' '.join(gold_tags)}\")\n",
    "    # print(f\"Predæ ‡ç­¾: {' '.join(pred_tags_seq)}\")\n",
    "    print(f\"Goldå®ä½“: {_format_entities(gold_entities)}\")\n",
    "    print(f\"Predå®ä½“: {_format_entities(pred_entities)}\")\n",
    "    \n",
    "    # æ£€æŸ¥é”™è¯¯\n",
    "    errors = []\n",
    "    for i, (gold, pred) in enumerate(zip(gold_tags, pred_tags_seq)):\n",
    "        if gold != pred:\n",
    "            errors.append(f\"ä½ç½®{i}({words[i]}): {gold}->{pred}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"æ ‡ç­¾é”™è¯¯: {', '.join(errors)}\")\n",
    "    else:\n",
    "        print(\"âœ“ æ— æ ‡ç­¾é”™è¯¯\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0d58c4886fcff01"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "# æŒ‰å®ä½“ç±»å‹ç»Ÿè®¡é”™è¯¯\n",
    "def analyze_entity_errors(results):\n",
    "    \"\"\"æŒ‰å®ä½“ç±»å‹åˆ†æé”™è¯¯\"\"\"\n",
    "    if not results:\n",
    "        return\n",
    "        \n",
    "    error_counter = results['error_counter']\n",
    "    \n",
    "    entity_errors = {\n",
    "        'LOC': {'total': 0, 'errors': []},\n",
    "        'PER': {'total': 0, 'errors': []},\n",
    "        'ORG': {'total': 0, 'errors': []}\n",
    "    }\n",
    "    \n",
    "    for error_type, count in error_counter.items():\n",
    "        # è§£æé”™è¯¯ç±»å‹ï¼Œå¦‚ \"B-LOC->O\"\n",
    "        parts = error_type.split('->')\n",
    "        if len(parts) == 2:\n",
    "            gold_tag = parts[0]\n",
    "            pred_tag = parts[1]\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦æ¶‰åŠå®ä½“æ ‡ç­¾\n",
    "            for entity_type in ['LOC', 'PER', 'ORG']:\n",
    "                if entity_type in gold_tag:\n",
    "                    entity_errors[entity_type]['total'] += count\n",
    "                    entity_errors[entity_type]['errors'].append((error_type, count))\n",
    "    \n",
    "    print(\"\\næŒ‰å®ä½“ç±»å‹ç»Ÿè®¡é”™è¯¯:\")\n",
    "    for entity_type, info in entity_errors.items():\n",
    "        print(f\"\\n{entity_type}å®ä½“é”™è¯¯:\")\n",
    "        print(f\"  æ€»é”™è¯¯æ•°: {info['total']}\")\n",
    "        for error_type, count in sorted(info['errors'], key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"    {error_type}: {count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-11-30T16:07:37.466931900Z"
    }
   },
   "id": "d6839291c65c3210"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# è·å–é”™è¯¯ç»Ÿè®¡çš„å‰nä¸ª\n",
    "def show_top_errors(results, top_n=10):\n",
    "    \"\"\"æ˜¾ç¤ºå‰Nä¸ªæœ€å¸¸è§çš„é”™è¯¯ç±»å‹\"\"\"\n",
    "    error_counter = results['error_counter']\n",
    "    print(f\"\\nå‰{top_n}ä¸ªæœ€å¸¸è§çš„é”™è¯¯ç±»å‹:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, (error_type, count) in enumerate(error_counter.most_common(top_n)):\n",
    "        print(f\"{i+1:2d}. {error_type}: {count} æ¬¡\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T15:43:49.900371800Z",
     "start_time": "2025-11-30T15:43:49.893708800Z"
    }
   },
   "id": "c6677f4a20934f4a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def analyze_sentences_by_error_severity(results, top_n=10):\n",
    "    sentences = results['sentences']\n",
    "    true_tags = results['true_tags']\n",
    "    pred_tags = results['pred_tags']\n",
    "    \n",
    "    # è®¡ç®—æ¯ä¸ªå¥å­çš„é”™è¯¯ç»Ÿè®¡\n",
    "    sentence_errors = []\n",
    "    \n",
    "    for i, (words, gold_tags, pred_tags_seq) in enumerate(zip(sentences, true_tags, pred_tags)):\n",
    "        # è®¡ç®—é”™è¯¯æ•°é‡\n",
    "        error_count = sum(1 for gold, pred in zip(gold_tags, pred_tags_seq) if gold != pred)\n",
    "        # è®¡ç®—é”™è¯¯ç‡\n",
    "        error_rate = error_count / len(words) if len(words) > 0 else 0\n",
    "        # è®¡ç®—å®ä½“çº§åˆ«çš„é”™è¯¯\n",
    "        gold_entities = _extract_entities_bmes_relaxed(words, gold_tags)\n",
    "        pred_entities = _extract_entities_bmes_relaxed(words, pred_tags_seq)\n",
    "        # å®ä½“åŒ¹é…åº¦ï¼ˆç®€å•çš„Jaccardç›¸ä¼¼åº¦ï¼‰\n",
    "        gold_entity_set = set((e['text'], e['type']) for e in gold_entities)\n",
    "        pred_entity_set = set((e['text'], e['type']) for e in pred_entities)\n",
    "        if len(gold_entity_set) + len(pred_entity_set) > 0:\n",
    "            entity_similarity = len(gold_entity_set & pred_entity_set) / len(gold_entity_set | pred_entity_set)\n",
    "        else:\n",
    "            entity_similarity = 1.0\n",
    "        # ä¸¥é‡ç¨‹åº¦è¯„åˆ†ï¼ˆé”™è¯¯ç‡æƒé‡ + å®ä½“é”™è¯¯æƒé‡ï¼‰\n",
    "        severity_score = error_rate * 0.6 + (1 - entity_similarity) * 0.4\n",
    "        sentence_errors.append({\n",
    "            'index': i,\n",
    "            'sentence': ''.join(words),\n",
    "            'words': words,\n",
    "            'gold_tags': gold_tags,\n",
    "            'pred_tags': pred_tags_seq,\n",
    "            'error_count': error_count,\n",
    "            'error_rate': error_rate,\n",
    "            'gold_entities': gold_entities,\n",
    "            'pred_entities': pred_entities,\n",
    "            'entity_similarity': entity_similarity,\n",
    "            'severity_score': severity_score\n",
    "        })\n",
    "    # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº\n",
    "    sentence_errors.sort(key=lambda x: x['severity_score'], reverse=True)\n",
    "    print(f\"\\nğŸ”´ é”™è¯¯æœ€ä¸¥é‡çš„å‰{top_n}ä¸ªå¥å­:\")\n",
    "    print(\"=\" * 80)\n",
    "    for i, sent_data in enumerate(sentence_errors[:top_n]):\n",
    "        print(f\"\\nğŸ“ å¥å­ #{i+1} (åŸå§‹ç´¢å¼•: {sent_data['index']})\")\n",
    "        print(f\"   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: {sent_data['severity_score']:.3f}\")\n",
    "        print(f\"   é”™è¯¯æ•°é‡: {sent_data['error_count']}/{len(sent_data['words'])}\")\n",
    "        print(f\"   é”™è¯¯ç‡: {sent_data['error_rate']:.1%}\")\n",
    "        print(f\"   å®ä½“ç›¸ä¼¼åº¦: {sent_data['entity_similarity']:.1%}\")\n",
    "        print(f\"   åŸæ–‡: {sent_data['sentence']}\")\n",
    "        # print(f\"   å­—/è¯: {' '.join(sent_data['words'])}\")   \n",
    "        \n",
    "        # æ˜¾ç¤ºå®ä½“å¯¹æ¯”\n",
    "        gold_entities_str = _format_entities(sent_data['gold_entities'])\n",
    "        pred_entities_str = _format_entities(sent_data['pred_entities'])\n",
    "        print(f\"   Goldå®ä½“: {gold_entities_str}\")\n",
    "        print(f\"   Predå®ä½“: {pred_entities_str}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:08:53.700501600Z",
     "start_time": "2025-11-30T16:08:53.695295Z"
    }
   },
   "id": "23223d3f953b4395"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def calculate_weighted_errors(results, top_n=20):\n",
    "    \"\"\"\n",
    "    è®¡ç®—åŠ æƒé”™è¯¯ç»Ÿè®¡ï¼Œè€ƒè™‘é”™è¯¯æ•°é‡å’Œæ ‡ç­¾åˆ†å¸ƒ\n",
    "    results : dict\n",
    "        è¯„ä¼°ç»“æœ\n",
    "    top_n : int\n",
    "        æ˜¾ç¤ºå‰Nä¸ªåŠ æƒé”™è¯¯ç±»å‹\n",
    "    \"\"\"\n",
    "    true_tags = results['true_tags']\n",
    "    pred_tags = results['pred_tags']\n",
    "    error_counter = results['error_counter']\n",
    "    # 1. ç»Ÿè®¡æ‰€æœ‰æ ‡ç­¾çš„åˆ†å¸ƒ\n",
    "    tag_distribution = Counter()\n",
    "    for tags in true_tags:\n",
    "        tag_distribution.update(tags)   \n",
    "    total_tags = sum(tag_distribution.values())\n",
    "    # 2. è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„å‡ºç°é¢‘ç‡\n",
    "    tag_frequency = {tag: count/total_tags for tag, count in tag_distribution.items()}\n",
    "    # 3. è®¡ç®—åŠ æƒé”™è¯¯åˆ†æ•°\n",
    "    weighted_errors = {}\n",
    "    for error_type, error_count in error_counter.items():\n",
    "        gold_tag, pred_tag = error_type.split('->')\n",
    "        # åŸºäºé‡‘æ ‡é¢‘ç‡çš„åŠ æƒ\n",
    "        # å¦‚æœæŸä¸ªæ ‡ç­¾æœ¬èº«å¾ˆå°‘å‡ºç°ï¼Œä½†é”™è¯¯å¾ˆå¤šï¼Œè¯´æ˜æ¨¡å‹å¯¹è¿™ä¸ªæ ‡ç­¾æŒæ¡ä¸å¥½\n",
    "        gold_frequency = tag_frequency.get(gold_tag, 0)\n",
    "        if gold_frequency > 0:\n",
    "            # é”™è¯¯ç‡ = é”™è¯¯æ•°é‡ / è¯¥æ ‡ç­¾æ€»å‡ºç°æ¬¡æ•°\n",
    "            error_rate = error_count / tag_distribution[gold_tag]\n",
    "            # åŠ æƒåˆ†æ•° = é”™è¯¯ç‡ * é”™è¯¯æ•°é‡ï¼ˆæ—¢è€ƒè™‘ç»å¯¹æ•°é‡ä¹Ÿè€ƒè™‘ç›¸å¯¹é”™è¯¯ç‡ï¼‰\n",
    "            weighted_score = error_rate * error_count\n",
    "        else:\n",
    "            weighted_score = 0\n",
    "        weighted_errors[error_type] = {\n",
    "            'count': error_count,\n",
    "            'gold_frequency': gold_frequency,\n",
    "            'error_rate': error_count / tag_distribution[gold_tag] if gold_tag in tag_distribution else 0,\n",
    "            'weighted_score': weighted_score\n",
    "        }\n",
    "    # 4. æŒ‰åŠ æƒåˆ†æ•°æ’åº\n",
    "    sorted_errors = sorted(weighted_errors.items(), \n",
    "                          key=lambda x: x[1]['weighted_score'], \n",
    "                          reverse=True)\n",
    "    \n",
    "    print(f\"\\nğŸ” åŠ æƒé”™è¯¯åˆ†æ (å‰{top_n}ä¸ª):\")\n",
    "    print(f\"{'æ’å':<4} {'é”™è¯¯ç±»å‹':<10} {'é”™è¯¯æ•°é‡':<6} {'æ ‡ç­¾é¢‘ç‡':<6} {'é”™è¯¯ç‡':<4} {'åŠ æƒåˆ†æ•°':<4}\")\n",
    "    \n",
    "    for i, (error_type, info) in enumerate(sorted_errors[:top_n]):\n",
    "        print(f\"{i+1:<4} {error_type:<15} {info['count']:<8} \"\n",
    "              f\"{info['gold_frequency']:.4f}  {info['error_rate']:.4f}   {info['weighted_score']:.2f}\")\n",
    "    \n",
    "    return weighted_errors, tag_distribution\n",
    "\n",
    "def comprehensive_error_analysis(results, top_n=20):\n",
    "    # 1.åŸºç¡€ç»Ÿè®¡\n",
    "    error_counter = results['error_counter']\n",
    "    total_errors = sum(error_counter.values())\n",
    "    print(f\"æ€»é”™è¯¯æ•°: {total_errors}\")\n",
    "    print(f\"é”™è¯¯ç±»å‹æ•°: {len(error_counter)}\")\n",
    "    # 2.åŠ æƒé”™è¯¯åˆ†æ\n",
    "    weighted_errors, tag_distribution = calculate_weighted_errors(results, top_n)\n",
    "    # 3.è¯†åˆ«ä¸¥é‡çš„é—®é¢˜\n",
    "    print(f\"\\nğŸš¨ ä¸¥é‡çš„æ¨¡å‹é—®é¢˜è¯†åˆ«:\")\n",
    "    # æ‰¾å‡ºé”™è¯¯ç‡è¶…è¿‡50%çš„æ ‡ç­¾\n",
    "    high_error_rate_tags = []\n",
    "    for error_type, info in weighted_errors.items():\n",
    "        if info['error_rate'] > 0.5 and info['count'] > 10:  # é”™è¯¯ç‡>50%ä¸”é”™è¯¯æ•°é‡>10\n",
    "            high_error_rate_tags.append((error_type, info['error_rate'], info['count']))\n",
    "    \n",
    "    high_error_rate_tags.sort(key=lambda x: x[1], reverse=True)\n",
    "    if high_error_rate_tags:\n",
    "        print(\"é«˜é”™è¯¯ç‡é—®é¢˜ (é”™è¯¯ç‡ > 50%):\")\n",
    "        for error_type, error_rate, count in high_error_rate_tags[:5]:\n",
    "            print(f\"  {error_type}: {error_rate:.1%} ({count}æ¬¡é”™è¯¯)\")\n",
    "    else:\n",
    "        print(\"æ²¡æœ‰å‘ç°é”™è¯¯ç‡è¶…è¿‡50%çš„ä¸¥é‡é—®é¢˜\")\n",
    "    return weighted_errors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:43:52.388917400Z",
     "start_time": "2025-11-30T16:43:52.382778800Z"
    }
   },
   "id": "1ac19bb55d86e691"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¼€å§‹æ¨¡å‹è¯„ä¼°...\n",
      "è¯»å–æ•°æ®...\n",
      "åŠ è½½æ¨¡å‹: F:\\GitHub\\named_entity_recognition\\ckpts\\bilstm_crf.pkl\n",
      "å¼€å§‹é¢„æµ‹...\n",
      "\n",
      "åŸºç¡€è¯„ä¼°æŒ‡æ ‡ï¼š\n",
      "          æ ‡ç­¾    precision       recall     f1-score      support\n",
      "     overall       0.8746       0.7941       0.8324        24143\n",
      "         LOC       0.8441       0.8330       0.8385         7564\n",
      "         ORG       0.8286       0.7874       0.8075         6181\n",
      "         PER       0.9328       0.7698       0.8435        10398\n",
      "æ€»é”™è¯¯æ•°: 6592\n",
      "é”™è¯¯ç±»å‹æ•°: 64\n",
      "\n",
      "ğŸ” åŠ æƒé”™è¯¯åˆ†æ (å‰10ä¸ª):\n",
      "æ’å   é”™è¯¯ç±»å‹       é”™è¯¯æ•°é‡   æ ‡ç­¾é¢‘ç‡   é”™è¯¯ç‡  åŠ æƒåˆ†æ•°\n",
      "1    E-PER->O        739      0.0137  0.2107   155.68\n",
      "2    M-ORG->O        769      0.0175  0.1718   132.15\n",
      "3    B-PER->O        630      0.0141  0.1756   110.65\n",
      "4    M-PER->O        558      0.0129  0.1689   94.27\n",
      "5    E-ORG->O        193      0.0033  0.2263   43.67\n",
      "6    M-LOC->O        284      0.0080  0.1391   39.50\n",
      "7    E-LOC->O        280      0.0108  0.1014   28.40\n",
      "8    B-LOC->O        259      0.0108  0.0938   24.30\n",
      "9    B-ORG->O        132      0.0033  0.1547   20.43\n",
      "10   B-ORG->B-LOC    55       0.0033  0.0645   3.55\n",
      "\n",
      "ğŸš¨ ä¸¥é‡çš„æ¨¡å‹é—®é¢˜è¯†åˆ«:\n",
      "æ²¡æœ‰å‘ç°é”™è¯¯ç‡è¶…è¿‡50%çš„ä¸¥é‡é—®é¢˜\n",
      "\n",
      "ğŸ”´ é”™è¯¯æœ€ä¸¥é‡çš„å‰10ä¸ªå¥å­:\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ å¥å­ #1 (åŸå§‹ç´¢å¼•: 860)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 1.000\n",
      "   é”™è¯¯æ•°é‡: 2/2\n",
      "   é”™è¯¯ç‡: 100.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: æ‰¬ä¸­\n",
      "   Goldå®ä½“: LOC:ã€æ‰¬ä¸­ã€[0-2]\n",
      "   Predå®ä½“: (æ— )\n",
      "\n",
      "ğŸ“ å¥å­ #2 (åŸå§‹ç´¢å¼•: 2945)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 1.000\n",
      "   é”™è¯¯æ•°é‡: 2/2\n",
      "   é”™è¯¯ç‡: 100.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: é—»ç™½\n",
      "   Goldå®ä½“: PER:ã€é—»ç™½ã€[0-2]\n",
      "   Predå®ä½“: (æ— )\n",
      "\n",
      "ğŸ“ å¥å­ #3 (åŸå§‹ç´¢å¼•: 2960)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 1.000\n",
      "   é”™è¯¯æ•°é‡: 12/12\n",
      "   é”™è¯¯ç‡: 100.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: ç™½æ±‚æ©çè´µæ–‡ç‰©å…¥è—æŠ—æˆ˜é¦†\n",
      "   Goldå®ä½“: PER:ã€ç™½æ±‚æ©ã€[0-3]\n",
      "   Predå®ä½“: LOC:ã€ç™½æ±‚æ©çè´µæ–‡ç‰©å…¥è—æŠ—æˆ˜é¦†ã€[0-12]\n",
      "\n",
      "ğŸ“ å¥å­ #4 (åŸå§‹ç´¢å¼•: 3175)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 1.000\n",
      "   é”™è¯¯æ•°é‡: 2/2\n",
      "   é”™è¯¯ç‡: 100.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: å…³æƒ…\n",
      "   Goldå®ä½“: (æ— )\n",
      "   Predå®ä½“: PER:ã€å…³æƒ…ã€[0-2]\n",
      "\n",
      "ğŸ“ å¥å­ #5 (åŸå§‹ç´¢å¼•: 6398)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 1.000\n",
      "   é”™è¯¯æ•°é‡: 3/3\n",
      "   é”™è¯¯ç‡: 100.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: å­˜æ–‡å­¦\n",
      "   Goldå®ä½“: PER:ã€å­˜æ–‡å­¦ã€[0-3]\n",
      "   Predå®ä½“: (æ— )\n",
      "\n",
      "ğŸ“ å¥å­ #6 (åŸå§‹ç´¢å¼•: 529)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 0.925\n",
      "   é”™è¯¯æ•°é‡: 7/8\n",
      "   é”™è¯¯ç‡: 87.5%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: é¦™æ¸¯å¥¥è¿é©¬æœ¯åœºé¦†\n",
      "   Goldå®ä½“: LOC:ã€é¦™æ¸¯ã€[0-2]\n",
      "   Predå®ä½“: LOC:ã€é¦™æ¸¯å¥¥è¿é©¬æœ¯åœºé¦†ã€[0-8]\n",
      "\n",
      "ğŸ“ å¥å­ #7 (åŸå§‹ç´¢å¼•: 572)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 0.914\n",
      "   é”™è¯¯æ•°é‡: 30/35\n",
      "   é”™è¯¯ç‡: 85.7%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: ä¸œæ–¹èˆªç©ºï¼‘ï¼–ä¸ªæµ·å¤–åŠäº‹å¤„è¢«å‘½åä¸ºä¸Šæµ·ä¸–åšä¼šä¸œæ–¹èˆªç©ºæµ·å¤–æ—…æ¸¸æ¨å¹¿å·¥ä½œç«™ã€‚\n",
      "   Goldå®ä½“: ORG:ã€ä¸Šæµ·ä¸–åšä¼šä¸œæ–¹èˆªç©ºæµ·å¤–æ—…æ¸¸æ¨å¹¿å·¥ä½œç«™ã€[16-34]\n",
      "   Predå®ä½“: ORG:ã€ä¸œæ–¹èˆªç©ºï¼‘ï¼–ä¸ªæµ·å¤–åŠäº‹å¤„ã€[0-12] | LOC:ã€ä¸Šæµ·ã€[16-18]\n",
      "\n",
      "ğŸ“ å¥å­ #8 (åŸå§‹ç´¢å¼•: 6335)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 0.914\n",
      "   é”™è¯¯æ•°é‡: 6/7\n",
      "   é”™è¯¯ç‡: 85.7%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: è®¿å±…é‡Œå¤«äººæ•…å±…\n",
      "   Goldå®ä½“: LOC:ã€å±…é‡Œå¤«äººæ•…å±…ã€[1-7]\n",
      "   Predå®ä½“: (æ— )\n",
      "\n",
      "ğŸ“ å¥å­ #9 (åŸå§‹ç´¢å¼•: 975)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 0.880\n",
      "   é”™è¯¯æ•°é‡: 4/5\n",
      "   é”™è¯¯ç‡: 80.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: æ¨ç‡•è’²é’Šèƒœ\n",
      "   Goldå®ä½“: PER:ã€æ¨ç‡•ã€[0-2] | PER:ã€è’²é’Šèƒœã€[2-5]\n",
      "   Predå®ä½“: PER:ã€æ¨ç‡•è’²ã€[0-3]\n",
      "\n",
      "ğŸ“ å¥å­ #10 (åŸå§‹ç´¢å¼•: 1090)\n",
      "   ä¸¥é‡ç¨‹åº¦è¯„åˆ†: 0.880\n",
      "   é”™è¯¯æ•°é‡: 12/15\n",
      "   é”™è¯¯ç‡: 80.0%\n",
      "   å®ä½“ç›¸ä¼¼åº¦: 0.0%\n",
      "   åŸæ–‡: ä¸­å›½ï¼ˆå»ŠåŠï¼‰å†œäº§å“äº¤æ˜“ä¼šå°†ä¸¾è¡Œ\n",
      "   Goldå®ä½“: LOC:ã€ä¸­å›½ã€[0-2] | LOC:ã€å»ŠåŠã€[3-5]\n",
      "   Predå®ä½“: ORG:ã€ä¸­å›½ï¼ˆå»ŠåŠï¼‰å†œäº§å“äº¤æ˜“ä¼šã€[0-12]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡Œè¯„ä¼°\n",
    "    print(\"å¼€å§‹æ¨¡å‹è¯„ä¼°...\")\n",
    "    results = evaluate_model()\n",
    "    if results:\n",
    "        # æŒ‰é”™è¯¯æ•°é‡æ’åº\n",
    "        #show_top_errors(results)\n",
    "        # æŒ‰é”™è¯¯ç‡æ’åº\n",
    "        weighted_results = comprehensive_error_analysis(results, top_n=10)\n",
    "        # æŒ‰å®ä½“ç±»å‹åˆ†æé”™è¯¯\n",
    "        #analyze_entity_errors(results)\n",
    "        # æŒ‰ä¸¥é‡ç¨‹åº¦å±•ç¤ºå‰nä¸ªå¥å­\n",
    "        analyze_sentences_by_error_severity(results, top_n=10)\n",
    "        # æŸ¥çœ‹ç‰¹å®šé”™è¯¯ç±»å‹\n",
    "        # interactive_error_analysis(results, 'B-PER->O')\n",
    "        # åˆ†æç‰¹å®šå¥å­\n",
    "        # compare_entities(results, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:44:10.056625Z",
     "start_time": "2025-11-30T16:43:52.783320900Z"
    }
   },
   "id": "8d81c075e9b3d387"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
